{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you know that you can classify text into distinct, predefined classes with LLMs like ChatGPT?\n",
    "\n",
    "Yes it's possible and I show you how. \n",
    "\n",
    "The big advantage is that these LLMs have a lot of knowledge and text understanding capabilites already encoded in their weights. This means that their ability to do text classification without any pre-training is really high. \n",
    "\n",
    "This is very interesting if you don't have a lot of labeled training data. \n",
    "\n",
    "First let's import all the libraries we need. We will also use OpenAIs API and their GPT-3.5-turbo model. Additionally we will leverage their function calling capabilities through a library called [instructor](https://github.com/jxnl/instructor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import enum \n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#load the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#load the API key\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to use another library called [\"pydantic\"](https://pydantic.dev/) to specifiy what data we want the LLM to return. We can leverage this to restrict the model output to the classes we want. \n",
    "\n",
    "For demonstrating how this works we'll use the [\"rotten_tomatoes\"](https://huggingface.co/datasets/rotten_tomatoes) dataset from [huggingface.co](https://huggingface.co). This is a dataset of movie reviews from the website [\"Rotten Tomatoes\"](https://www.rottentomatoes.com/). The movie reviews are either \"positive\" or \"negative\" and the task is to classify the movie reviews in one of these two categories. \n",
    "\n",
    "Further, we will only use a subset of 100 randomly chosen examples for demonstration purposes here. \n",
    "\n",
    "The labels are encoded as integeres with 0 = 'negative' and 1 = 'positive'. With the `itol` dict we map the integers to the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('there has always been something likable about the marquis de sade .',\n",
       " 'positive')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "subset = dataset[\"train\"].shuffle().select(range(100)) # random subset of 100 examples\n",
    "\n",
    "# convert the integers to labels\n",
    "itol = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "# an example of the data\n",
    "subset[\"text\"][2], itol[subset[\"label\"][2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we come to the heart of the whole idea.\n",
    "\n",
    "We leverage data types to describe the data we want to receive back from the model. \n",
    "\n",
    "We use an `Enum` to implement our labels `POSITIVE` and `NEGATIVE`. Then we implement a `pydantic` `BaseModel` that describes what the prediction of the LLM should encapsulate. In our very simple case this is just the predicted `class_label`, which is of type `Labels`. \n",
    "\n",
    "Note that the docstring here has a function that goes further than just providing documentation. Since the docstring will be part of the schema of the `SinglePrediction` class and the schema will be passed to the LLM, it gives further information to the LLM what this class represents and what the LLM should do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'Labels': {'enum': ['positive', 'negative'],\n",
       "   'title': 'Labels',\n",
       "   'type': 'string'}},\n",
       " 'description': 'Correct class label for the given text',\n",
       " 'properties': {'class_label': {'$ref': '#/$defs/Labels'}},\n",
       " 'required': ['class_label'],\n",
       " 'title': 'SinglePrediction',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Labels(str, enum.Enum):\n",
    "    POSITIVE = \"positive\"\n",
    "    NEGATIVE = \"negative\"\n",
    "    \n",
    "class SinglePrediction(BaseModel):\n",
    "    \"\"\"\n",
    "    Correct class label for the given text\n",
    "    \"\"\"\n",
    "\n",
    "    class_label: Labels\n",
    "\n",
    "SinglePrediction.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `instructor` library works by \"patching\" the `openai` client and expanding its functionality. We just call the `instructor.patch()` function with the `OpenAI()` class as its sole argument and use this as our `client`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.patch(OpenAI())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can implement the `classify` function that takes in the data we want to classify (our movie reviews) and return an instance of the `SinglePrediction` class we implemented above. \n",
    "\n",
    "The code is quite simple and should be familiar to you if you have already used the OpenAI api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data: str) -> SinglePrediction:\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        temperature=0.4,\n",
    "        response_model=SinglePrediction,\n",
    "        messages=[\n",
    "             {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a world class algorithm to identify the sentiment of movie reviews.\",\n",
    "            },\n",
    "\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Classify the sentiment of the following movie review: {data}\",\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy based on preds and targets\n",
    "def accuracy(preds, targets):\n",
    "    return np.sum(np.array(preds) == np.array(targets)) / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:13<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = [classify(t).class_label.value for t in tqdm(subset[\"text\"])]\n",
    "targets = [itol[l] for l in subset[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, targets) # 0.88 ... well, that's much better than random guessing and remember this is without any training. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
